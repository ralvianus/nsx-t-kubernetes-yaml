---
# Yaml template for nsx-node-agent and nsx-kube-proxy DaemonSet
# Proper kubernetes API parameters and NCP Docker image must be
# specified.
# This yaml file is part of NCP 2.5.0 release.

# ConfigMap for ncp.ini
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsx-node-agent-config
  namespace: nsx-system
  labels:
    version: v1
data:
  ncp.ini: |

    [DEFAULT]

    # If set to true, the logging level will be set to DEBUG instead of the
    # default INFO level.
    #debug = False

    # If set to true, log output to standard error.
    #use_stderr = True

    # If set to true, use syslog for logging.
    #use_syslog = False

    # The base directory used for relative log_file paths.
    #log_dir = <None>

    # Name of log file to send logging output to.
    #log_file = <None>

    # max MB for each compressed file. Defaults to 100 MB.
    #log_rotation_file_max_mb = 100

    # Total number of compressed backup files to store. Defaults to 5.
    #log_rotation_backup_count = 5

    # Specify the directory where nsx-python-logging is installed
    #nsx_python_logging_path = /opt/vmware/nsx-common/python

    # Specify the directory where nsx-cli is installed
    #nsx_cli_path = /opt/vmware/nsx-cli/bin/python


    [k8s]

    # Kubernetes API server IP address.
    apiserver_host_ip = 192.168.110.11

    # Kubernetes API server port.
    apiserver_host_port = 6443

    # Full path of the Token file to use for authenticating with the k8s API
    # server.
    client_token_file = /var/run/secrets/kubernetes.io/serviceaccount/token

    # Full path of the client certificate file to use for authenticating with
    # the k8s API server. It must be specified together with
    # "client_private_key_file".
    #client_cert_file = <None>

    # Full path of the client private key file to use for authenticating with
    # the k8s API server. It must be specified together with
    # "client_cert_file".
    #client_private_key_file = <None>

    # Specify a CA bundle file to use in verifying the k8s API server
    # certificate.
    ca_file = /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

    # Specify whether ingress controllers are expected to be deployed in
    # hostnework mode or as regular pods externally accessed via NAT
    # Choices: hostnetwork nat
    #ingress_mode = hostnetwork

    # Log level for the kubernetes adaptor
    # Choices: NOTSET DEBUG INFO WARNING ERROR CRITICAL
    #loglevel = <None>

    # The default HTTP ingress port
    #http_ingress_port = 80

    # The default HTTPS ingress port
    #https_ingress_port = 443


    # Specify thread pool size to process resource events
    #resource_watcher_thread_pool_size = 1

    # User specified IP address for HTTP and HTTPS ingresses
    #http_and_https_ingress_ip = <None>

    # Set this to True to enable NCP to create segment port for VM through
    # NsxNetworkInterface CRD.
    #enable_nsx_netif_crd = False

    # Option to set the type of baseline cluster policy. ALLOW_CLUSTER creates
    # an explicit baseline policy to allow any pod to communicate any other pod
    # within the cluster. ALLOW_NAMESPACE creates an explicit baseline policy
    # to allow pods within the same namespace to communicate with each other.
    # By default, no baseline rule will be created and the cluster will assume
    # the default behavior as specified by the backend.
    # Choices: <None> allow_cluster allow_namespace
    #baseline_policy_type = <None>


    [coe]

    # Container orchestrator adaptor to plug in.
    #adaptor = kubernetes

    # Specify cluster for adaptor.
    cluster = kube-cluster

    # Log level for NCP operations
    # Choices: NOTSET DEBUG INFO WARNING ERROR CRITICAL
    loglevel = INFO

    # Log level for NSX API client operations
    # Choices: NOTSET DEBUG INFO WARNING ERROR CRITICAL
    #nsxlib_loglevel = <None>

    # Enable SNAT for all projects in this cluster
    #enable_snat = True

    # Option to enable profiling
    #profiling = False

    # The type of container host node
    # Choices: HOSTVM BAREMETAL CLOUD WCP_WORKER
    node_type = BAREMETAL

    # The time in seconds for NCP/nsx_node_agent to recover the connection to
    # NSX manager/container orchestrator adaptor/Hyperbus before exiting. If
    # the value is 0, NCP/nsx_node_agent won't exit automatically when the
    # connection check fails
    #connect_retry_timeout = 0



    [nsx_kube_proxy]

    # The way to process service configuration, set into OVS flow or write to
    # nestdb,
    # Choices: ovs nestdb
    #config_handler = ovs


    [nsx_node_agent]

    # Prefix of node /proc path to mount on nsx_node_agent DaemonSet
    #proc_mount_path_prefix = /host




    # The log level of NSX RPC library
    # Choices: NOTSET DEBUG INFO WARNING ERROR CRITICAL
    #nsxrpc_loglevel = ERROR

    # OVS bridge name
    #ovs_bridge = br-int

    # The time in seconds for nsx_node_agent to wait CIF config from HyperBus
    # before returning to CNI
    #config_retry_timeout = 300

    # The time in seconds for nsx_node_agent to backoff before re-using an
    # existing cached CIF to serve CNI request. Must be less than
    # config_retry_timeout.
    #config_reuse_backoff_time = 15

    # The path for OpenvSwitch db socket
    #ovs_db_sock = unix:/var/run/openvswitch/db.sock

    # The OVS uplink OpenFlow port where to apply the NAT rules to.
    #ovs_uplink_port = <None>



---
# nsx-ncp-bootstrap DaemonSet
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: nsx-ncp-bootstrap
  namespace: nsx-system
  labels:
    tier: nsx-networking
    component: nsx-ncp-bootstrap
    version: v1
spec:
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        tier: nsx-networking
        component: nsx-ncp-bootstrap
        version: v1
    spec:
      hostNetwork: true
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        - key: node.kubernetes.io/not-ready
          effect: NoSchedule
        - key: node.kubernetes.io/unreachable
          effect: NoSchedule
      hostPID: true
      # If configured with ServiceAccount, update the ServiceAccount
      # name below.
      serviceAccountName: nsx-node-agent-svc-account
      initContainers:
        - name: nsx-ncp-bootstrap
          # Docker image for NCP
          image: nsx-ncp
          imagePullPolicy: IfNotPresent
          # override NCP image entrypoint
          command: ["init_k8s_node"]


          securityContext:
            # to move the IP from ovs_bridge to ovs_uplink_port
            capabilities:
              add:
                - NET_ADMIN

          volumeMounts:
          # required to read the ovs_uplink_port
          - name: config-volume
            mountPath: /etc/nsx-ujo/ncp.ini
            subPath: ncp.ini
          # mounts to which NSX-CNI are copied BEGIN
          - name: host-etc
            mountPath: /host/etc
          - name: host-opt
            mountPath: /host/opt
          - name: host-var
            mountPath: /host/var
          # mounts to which NSX-CNI are copied END
          # mount host's OS info to identify host OS
          - name: host-os-release
            mountPath: /host/etc/os-release
          # mount host lib modules to install OVS kernel module if needed
          - name: host-modules
            mountPath: /lib/modules
          # mount openvswitch database
          - name: host-config-openvswitch
            mountPath: /etc/openvswitch
          # mount ovs runtime files
          - name: openvswitch
            mountPath: /var/run/openvswitch
          - name: dir-tmp-usr-ovs-kmod-backup
          # we move the usr kmod files to this dir temporarily before installing
          # new OVS kmod and/or backing up existing OVS kmod backup
            mountPath: /tmp/nsx_usr_ovs_kmod_backup


          # mount to which an OVS kmod file is copied.
          - name: host-usr-share
            mountPath: /host/usr/share
          # mount host's rpm package database to remove nsx-cni if installed
          - name: rpm-lib
            mountPath: /var/lib/rpm
          - name: usr-lib-rpm
            mountPath: /usr/lib/rpm
          # mount host's modinfo to know if a module is installed on the host
          - name: host-modinfo
            mountPath: /usr/sbin/modinfo
            readOnly: true
          # mount host's depmod to create module dependencies after creating
          # new OVS kmod files
          - name: host-depmod
            mountPath: /sbin/depmod

      containers:
        - name: nsx-dummy
          # This container is of no use.
          # Docker image for NCP
          image: nsx-ncp
          imagePullPolicy: IfNotPresent
          # override NCP image entrypoint
          command: ["/bin/bash", "-c", "while true; do sleep 5; done"]
      volumes:
        - name: config-volume
          configMap:
            name: nsx-node-agent-config
        - name: host-etc
          hostPath:
            path: /etc
        - name: host-opt
          hostPath:
            path: /opt
        - name: host-var
          hostPath:
            path: /var
        - name: host-os-release
          hostPath:
            path: /etc/os-release
        - name: host-modules
          hostPath:
            path: /lib/modules
        - name: host-config-openvswitch
          hostPath:
            path: /etc/openvswitch
        - name: openvswitch
          hostPath:
            path: /var/run/openvswitch
        - name: dir-tmp-usr-ovs-kmod-backup
          hostPath:
            path: /tmp/nsx_usr_ovs_kmod_backup


        - name: host-usr-share
          hostPath:
            path: /usr/share
        - name: rpm-lib
          hostPath:
            path: /var/lib/rpm
        - name: usr-lib-rpm
          hostPath:
            path: /usr/lib/rpm
        - name: host-modinfo
          hostPath:
            path: /usr/sbin/modinfo
        - name: host-depmod
          hostPath:
            path: /sbin/depmod

---
# nsx-node-agent DaemonSet
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: nsx-node-agent
  namespace: nsx-system
  labels:
    tier: nsx-networking
    component: nsx-node-agent
    version: v1
spec:
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:

      labels:
        tier: nsx-networking
        component: nsx-node-agent
        version: v1
    spec:
      hostNetwork: true
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        - key: node.kubernetes.io/not-ready
          effect: NoSchedule
        - key: node.kubernetes.io/unreachable
          effect: NoSchedule
      # If configured with ServiceAccount, update the ServiceAccount
      # name below.
      serviceAccountName: nsx-node-agent-svc-account
      terminationGracePeriodSeconds: 120
      containers:

        - name: nsx-node-agent
          # Docker image for NCP
          image: nsx-ncp
          imagePullPolicy: IfNotPresent
          # override NCP image entrypoint
          command: ["start_node_agent"]
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - timeout 5 check_pod_liveness nsx-node-agent
            initialDelaySeconds: 5
            timeoutSeconds: 5
            periodSeconds: 10
            failureThreshold: 5
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
                - SYS_ADMIN
                - SYS_PTRACE
                - DAC_READ_SEARCH
          volumeMounts:
          # ncp.ini
          - name: config-volume
            mountPath: /etc/nsx-ujo/ncp.ini
            subPath: ncp.ini
            readOnly: true
          # mount openvswitch dir
          - name: openvswitch
            mountPath: /var/run/openvswitch
          # mount CNI socket path
          - name: cni-sock
            mountPath: /var/run/nsx-ujo
          # mount container namespace
          - name: netns
            mountPath: /var/run/netns
          # mount host proc
          - name: proc
            mountPath: /host/proc
            readOnly: true

        - name: nsx-kube-proxy
          # Docker image for NCP
          image: nsx-ncp
          imagePullPolicy: IfNotPresent
          # override NCP image entrypoint
          command: ["start_kube_proxy"]
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - timeout 5 check_pod_liveness nsx-kube-proxy
            initialDelaySeconds: 5
            periodSeconds: 5
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
                - SYS_ADMIN
                - SYS_PTRACE
                - DAC_READ_SEARCH

          volumeMounts:
          # ncp.ini
          - name: config-volume
            mountPath: /etc/nsx-ujo/ncp.ini
            subPath: ncp.ini
            readOnly: true

          # mount openvswitch dir
          - name: openvswitch
            mountPath: /var/run/openvswitch


        # nsx-ovs is not needed on BAREMETAL
        - name: nsx-ovs
          # Docker image for NCP
          image: nsx-ncp
          imagePullPolicy: IfNotPresent
          # override NCP image entrypoint
          command: ["start_ovs"]
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
                - SYS_ADMIN
                - SYS_NICE
                - SYS_MODULE
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                # You must pass --allowOVSOnHost if you are running OVS on the
                # host before the installation. This allows livelinessProbe to
                # succeed and container won't restart frequently.
                - timeout 5 check_pod_liveness nsx-ovs
            initialDelaySeconds: 5
            periodSeconds: 5
          volumeMounts:
          # ncp.ini
          - name: config-volume
            mountPath: /etc/nsx-ujo/ncp.ini
            subPath: ncp.ini
            readOnly: true
          # mount openvswitch dir
          - name: openvswitch
            mountPath: /var/run/openvswitch
          # mount host sys dir
          - name: host-sys
            mountPath: /sys
            readOnly: true
          # mount host config openvswitch dir
          - name: host-config-openvswitch
            mountPath: /etc/openvswitch
          # mount host lib modules to insert OVS kernel module if needed
          - name: host-modules
            mountPath: /lib/modules
            readOnly: true
          # mount host's OS info to identify host OS
          - name: host-os-release
            mountPath: /host/etc/os-release
            readOnly: true

          # mount host's modinfo to know if a module is installed on the host
          - name: host-modinfo
            mountPath: /usr/sbin/modinfo
            readOnly: true


      volumes:
        - name: config-volume
          configMap:
            name: nsx-node-agent-config

        - name: openvswitch
          hostPath:
            path: /var/run/openvswitch
        - name: cni-sock
          hostPath:
            path: /var/run/nsx-ujo
        - name: netns
          hostPath:
            path: /var/run/netns
        - name: proc
          hostPath:
            path: /proc


        - name: host-sys
          hostPath:
            path: /sys
        - name: host-modules
          hostPath:
            path: /lib/modules
        - name: host-config-openvswitch
          hostPath:
            path: /etc/openvswitch
        - name: host-os-release
          hostPath:
            path: /etc/os-release

        - name: host-modinfo
          hostPath:
            path: /usr/sbin/modinfo
        - name: host-depmod
          hostPath:
            path: /sbin/depmod
